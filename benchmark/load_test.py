import requests
import time
import statistics
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

# å‹æµ‹é…ç½®
API_URL = "http://localhost:8000/query"
CONCURRENCY = 10  # 10å¹¶å‘
TOTAL_REQUESTS = 100  # æ€»è¯·æ±‚æ•°
DURATION = 300  # 5åˆ†é’Ÿå‹æµ‹

# æµ‹è¯•queryåˆ—è¡¨
TEST_QUERIES = [
    "ä»€ä¹ˆæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Ÿ",
    "vLLMçš„æ ¸å¿ƒä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
    "Llama2æ¨¡å‹æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ",
    "å¦‚ä½•ä¼˜åŒ–å¤§æ¨¡å‹æ¨ç†æ€§èƒ½ï¼Ÿ",
    "PagedAttentionçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
    "RAGæŠ€æœ¯è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
    "å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å¦‚ä½•æå‡æ¨¡å‹ååé‡ï¼Ÿ",
]

class LoadTester:
    def __init__(self):
        self.results = []
        self.errors = 0
        self.start_time = None
        
    def send_request(self, query_idx):
        """å‘é€å•ä¸ªè¯·æ±‚"""
        query = TEST_QUERIES[query_idx % len(TEST_QUERIES)]
        
        try:
            start = time.time()
            response = requests.post(
                API_URL,
                json={"question": query, "top_k": 3},
                timeout=30
            )
            end = time.time()
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "success": True,
                    "query": query,
                    "total_time": end - start,
                    "retrieval_time": data["retrieval_time"],
                    "generation_time": data["generation_time"],
                    "ttft": None  # APIå±‚é¢æ— æ³•ç›´æ¥æµ‹é‡TTFT
                }
            else:
                self.errors += 1
                return {"success": False, "error": response.status_code}
                
        except Exception as e:
            self.errors += 1
            return {"success": False, "error": str(e)}
    
    def run_load_test(self, num_requests, concurrency):
        """æ‰§è¡Œå‹æµ‹"""
        print("="*80)
        print(f"ğŸ“Š å¼€å§‹å‹æµ‹")
        print(f"   - æ€»è¯·æ±‚æ•°: {num_requests}")
        print(f"   - å¹¶å‘æ•°: {concurrency}")
        print(f"   - æŸ¥è¯¢ç±»å‹: {len(TEST_QUERIES)}ç§")
        print("="*80 + "\n")
        
        self.start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = [
                executor.submit(self.send_request, i) 
                for i in range(num_requests)
            ]
            
            completed = 0
            for future in as_completed(futures):
                result = future.result()
                if result["success"]:
                    self.results.append(result)
                
                completed += 1
                if completed % 10 == 0:
                    print(f"â³ å·²å®Œæˆ: {completed}/{num_requests} è¯·æ±‚")
        
        total_duration = time.time() - self.start_time
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(total_duration)
    
    def generate_report(self, total_duration):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚ï¼")
            return
        
        # æå–æ—¶é—´æ•°æ®
        total_times = [r["total_time"] for r in self.results]
        retrieval_times = [r["retrieval_time"] for r in self.results]
        generation_times = [r["generation_time"] for r in self.results]
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        def calc_percentile(data, percentile):
            sorted_data = sorted(data)
            index = int(len(sorted_data) * percentile / 100)
            return sorted_data[min(index, len(sorted_data) - 1)]
        
        report = {
            "test_config": {
                "total_requests": len(self.results) + self.errors,
                "successful_requests": len(self.results),
                "failed_requests": self.errors,
                "concurrency": CONCURRENCY,
                "duration": f"{total_duration:.2f}s"
            },
            "throughput": {
                "qps": len(self.results) / total_duration,
                "avg_response_time": statistics.mean(total_times)
            },
            "latency": {
                "total_time": {
                    "min": min(total_times),
                    "max": max(total_times),
                    "mean": statistics.mean(total_times),
                    "median": statistics.median(total_times),
                    "p95": calc_percentile(total_times, 95),
                    "p99": calc_percentile(total_times, 99)
                },
                "retrieval_time": {
                    "mean": statistics.mean(retrieval_times),
                    "p99": calc_percentile(retrieval_times, 99)
                },
                "generation_time": {
                    "mean": statistics.mean(generation_times),
                    "p99": calc_percentile(generation_times, 99)
                }
            }
        }
        
        # æ‰“å°æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ“Š å‹æµ‹ç»“æœæŠ¥å‘Š")
        print("="*80 + "\n")
        
        print("ã€æµ‹è¯•é…ç½®ã€‘")
        print(f"  æ€»è¯·æ±‚æ•°: {report['test_config']['total_requests']}")
        print(f"  æˆåŠŸè¯·æ±‚: {report['test_config']['successful_requests']}")
        print(f"  å¤±è´¥è¯·æ±‚: {report['test_config']['failed_requests']}")
        print(f"  å¹¶å‘æ•°: {report['test_config']['concurrency']}")
        print(f"  æµ‹è¯•æ—¶é•¿: {report['test_config']['duration']}\n")
        
        print("ã€ååé‡æŒ‡æ ‡ã€‘")
        print(f"  QPS: {report['throughput']['qps']:.2f} è¯·æ±‚/ç§’")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {report['throughput']['avg_response_time']:.3f}ç§’\n")
        
        print("ã€å»¶è¿ŸæŒ‡æ ‡ - ç«¯åˆ°ç«¯ã€‘")
        print(f"  æœ€å°å€¼: {report['latency']['total_time']['min']:.3f}ç§’")
        print(f"  æœ€å¤§å€¼: {report['latency']['total_time']['max']:.3f}ç§’")
        print(f"  å¹³å‡å€¼: {report['latency']['total_time']['mean']:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {report['latency']['total_time']['median']:.3f}ç§’")
        print(f"  P95: {report['latency']['total_time']['p95']:.3f}ç§’")
        print(f"  P99: {report['latency']['total_time']['p99']:.3f}ç§’\n")
        
        print("ã€å»¶è¿ŸæŒ‡æ ‡ - æ£€ç´¢ã€‘")
        print(f"  å¹³å‡æ£€ç´¢æ—¶é—´: {report['latency']['retrieval_time']['mean']:.3f}ç§’")
        print(f"  P99æ£€ç´¢æ—¶é—´: {report['latency']['retrieval_time']['p99']:.3f}ç§’\n")
        
        print("ã€å»¶è¿ŸæŒ‡æ ‡ - ç”Ÿæˆã€‘")
        print(f"  å¹³å‡ç”Ÿæˆæ—¶é—´: {report['latency']['generation_time']['mean']:.3f}ç§’")
        print(f"  P99ç”Ÿæˆæ—¶é—´: {report['latency']['generation_time']['p99']:.3f}ç§’\n")
        
        # ä¿å­˜JSONæŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"load_test_report_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'report': report,
                'raw_results': self.results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        print("="*80 + "\n")
        
        return report

if __name__ == "__main__":
    # ç­‰å¾…APIæœåŠ¡å™¨å¯åŠ¨
    print("â³ ç­‰å¾…APIæœåŠ¡å™¨å°±ç»ª...")
    time.sleep(5)
    
    # å¥åº·æ£€æŸ¥
    try:
        response = requests.get("http://localhost:8000/")
        print(f"âœ… APIæœåŠ¡å™¨çŠ¶æ€: {response.json()}\n")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨: {e}")
        print("è¯·å…ˆå¯åŠ¨APIæœåŠ¡å™¨: python api_server.py")
        exit(1)
    
    # æ‰§è¡Œå‹æµ‹
    tester = LoadTester()
    tester.run_load_test(
        num_requests=100,
        concurrency=10
    )