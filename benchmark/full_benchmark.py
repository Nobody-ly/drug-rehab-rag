import asyncio
import time
import statistics
import json
from datetime import datetime
from enhanced_rag_system import EnhancedRAGSystem

# æˆ’æ¯’ç›¸å…³æµ‹è¯•é—®é¢˜ï¼ˆ10ä¸ªï¼‰
TEST_QUERIES = [
    "ä»€ä¹ˆæ˜¯å¼ºåˆ¶éš”ç¦»æˆ’æ¯’ï¼Ÿ",
    "ç¤¾åŒºæˆ’æ¯’çš„é€‚ç”¨æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æˆ’æ¯’äººå‘˜æœ‰å“ªäº›æƒåˆ©å’Œä¿éšœï¼Ÿ",
    "æˆ’æ¯’æœŸé™ä¸€èˆ¬æ˜¯å¤šä¹…ï¼Ÿ",
    "å¦‚ä½•ç”³è¯·è‡ªæ„¿æˆ’æ¯’ï¼Ÿ",
    "æˆ’æ¯’åœºæ‰€åº”å½“æä¾›å“ªäº›æœåŠ¡ï¼Ÿ",
    "ç¦æ¯’æ³•çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å¸æ¯’æˆç˜¾çš„è®¤å®šæ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æˆ’æ¯’åº·å¤äººå‘˜å°±ä¸šæœ‰ä»€ä¹ˆæ”¿ç­–ï¼Ÿ",
    "å®¶å±å¯ä»¥æ¢è§†æˆ’æ¯’äººå‘˜å—ï¼Ÿ",
]

CONCURRENCY = 10   # å¹¶å‘æ•°
TOTAL_REQUESTS = 30  # æ€»è¯·æ±‚æ•°

class RAGBenchmark:
    def __init__(self):
        self.rag = EnhancedRAGSystem()
        
    async def initialize(self):
        await self.rag.initialize(
            gpu_memory_utilization=0.87,
            max_num_batched_tokens=8192,
            max_num_seqs=64
        )
    
    async def single_request(self, query: str, method: str, request_id: int):
        """å•ä¸ªè¯·æ±‚"""
        try:
            result = await self.rag.query(query, method=method, max_tokens=512)
            result['request_id'] = request_id
            result['success'] = True
            result['query'] = query
            return result
        except Exception as e:
            print(f"âŒ è¯·æ±‚ {request_id} å¤±è´¥: {e}")
            return {
                'request_id': request_id,
                'query': query,
                'success': False,
                'error': str(e)
            }
    
    async def run_benchmark(self, method: str):
        """è¿è¡Œå‹æµ‹"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æµ‹è¯•æ–¹æ³•: {method}")
        print(f"æ€»è¯·æ±‚æ•°: {TOTAL_REQUESTS} | å¹¶å‘æ•°: {CONCURRENCY}")
        print(f"{'='*80}\n")
        
        start_time = time.time()
        
        # åˆ›å»ºä»»åŠ¡
        tasks = []
        for i in range(TOTAL_REQUESTS):
            query = TEST_QUERIES[i % len(TEST_QUERIES)]
            task = self.single_request(query, method, i)
            tasks.append(task)
        
        # é™åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(CONCURRENCY)
        
        async def bounded_task(task):
            async with semaphore:
                return await task
        
        results = await asyncio.gather(*[bounded_task(task) for task in tasks])
        
        duration = time.time() - start_time
        
        print(f"âœ… æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’\n")
        
        return self.analyze_results(results, duration, method)
    
    def analyze_results(self, results, duration, method):
        """åˆ†æç»“æœ"""
        success_results = [r for r in results if r.get('success', False)]
        
        if not success_results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚")
            return None
        
        # æå–æŒ‡æ ‡
        total_times = [r['total_time'] for r in success_results]
        retrieval_times = [r['retrieval_time'] for r in success_results]
        rerank_times = [r.get('rerank_time', 0) for r in success_results]
        generation_times = [r['generation_time'] for r in success_results]
        ttfts = [r['ttft'] for r in success_results]
        
        def percentile(data, p):
            sorted_data = sorted(data)
            idx = int(len(sorted_data) * p / 100)
            return sorted_data[min(idx, len(sorted_data) - 1)]
        
        stats = {
            'method': method,
            'test_duration': duration,
            'total_requests': len(results),
            'successful_requests': len(success_results),
            'success_rate': len(success_results) / len(results) * 100,
            'qps': len(success_results) / duration,
            'total_time': {
                'mean': statistics.mean(total_times),
                'median': statistics.median(total_times),
                'min': min(total_times),
                'max': max(total_times),
                'p95': percentile(total_times, 95),
                'p99': percentile(total_times, 99)
            },
            'retrieval_time': {
                'mean': statistics.mean(retrieval_times),
                'median': statistics.median(retrieval_times),
                'p95': percentile(retrieval_times, 95)
            },
            'rerank_time': {
                'mean': statistics.mean([t for t in rerank_times if t > 0]) if any(rerank_times) else 0,
                'median': statistics.median([t for t in rerank_times if t > 0]) if any(rerank_times) else 0
            },
            'generation_time': {
                'mean': statistics.mean(generation_times),
                'median': statistics.median(generation_times),
                'p99': percentile(generation_times, 99)
            },
            'ttft': {
                'mean': statistics.mean(ttfts),
                'median': statistics.median(ttfts),
                'min': min(ttfts),
                'max': max(ttfts),
                'p95': percentile(ttfts, 95),
                'p99': percentile(ttfts, 99)
            }
        }
        
        self.print_stats(stats)
        return stats, success_results  # è¿”å›åŸå§‹ç»“æœç”¨äºè´¨é‡è¯„ä¼°
    
    def print_stats(self, stats):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡ - {stats['method']}")
        print(f"{'='*80}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"QPS: {stats['qps']:.2f}")
        print(f"\nã€æ€»å“åº”æ—¶é—´ã€‘")
        print(f"  å¹³å‡: {stats['total_time']['mean']:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {stats['total_time']['median']:.3f}ç§’")
        print(f"  P95: {stats['total_time']['p95']:.3f}ç§’")
        print(f"  P99: {stats['total_time']['p99']:.3f}ç§’")
        print(f"\nã€æ£€ç´¢æ—¶é—´ã€‘")
        print(f"  å¹³å‡: {stats['retrieval_time']['mean']:.3f}ç§’")
        print(f"  P95: {stats['retrieval_time']['p95']:.3f}ç§’")
        if stats['rerank_time']['mean'] > 0:
            print(f"\nã€é‡æ’æ—¶é—´ã€‘")
            print(f"  å¹³å‡: {stats['rerank_time']['mean']:.3f}ç§’")
            print(f"  ä¸­ä½æ•°: {stats['rerank_time']['median']:.3f}ç§’")
        print(f"\nã€ç”Ÿæˆæ—¶é—´ã€‘")
        print(f"  å¹³å‡: {stats['generation_time']['mean']:.3f}ç§’")
        print(f"  P99: {stats['generation_time']['p99']:.3f}ç§’")
        print(f"\nã€TTFTï¼ˆé¦–å­—å»¶è¿Ÿï¼‰ã€‘")
        print(f"  å¹³å‡: {stats['ttft']['mean']:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {stats['ttft']['median']:.3f}ç§’")
        print(f"  P95: {stats['ttft']['p95']:.3f}ç§’")
        print(f"  P99: {stats['ttft']['p99']:.3f}ç§’")
        print("="*80 + "\n")

async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ¯ æˆ’æ¯’çŸ¥è¯†åº“RAGç³»ç»Ÿå®Œæ•´å‹æµ‹")
    print("="*80)
    
    benchmark = RAGBenchmark()
    await benchmark.initialize()
    
    # æµ‹è¯•ä¸‰ç§æ–¹æ³•
    methods = ["baseline", "rerank", "hybrid_rerank"]
    all_stats = []
    all_results_dict = {}
    
    for i, method in enumerate(methods, 1):
        print(f"\n[{i}/{len(methods)}] å¼€å§‹æµ‹è¯•: {method}")
        stats, results = await benchmark.run_benchmark(method)
        
        if stats:
            all_stats.append(stats)
            all_results_dict[method] = results
        
        # ç­‰å¾…GPUå†·å´
        if i < len(methods):
            print("â³ ç­‰å¾…5ç§’è®©GPUå†·å´...\n")
            await asyncio.sleep(5)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(all_stats, all_results_dict)

def generate_comparison_report(all_stats, all_results_dict):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“Š æ–¹æ³•å¯¹æ¯”æ€»ç»“")
    print("="*80 + "\n")
    
    if not all_stats:
        print("âŒ æ²¡æœ‰å¯ç”¨ç»“æœ")
        return
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print(f"{'æ–¹æ³•':<25} {'QPS':<10} {'å¹³å‡å“åº”':<12} {'P99å“åº”':<12} {'P99 TTFT':<12}")
    print("-" * 80)
    
    baseline = all_stats[0]
    
    for stat in all_stats:
        print(f"{stat['method']:<25} "
              f"{stat['qps']:<10.2f} "
              f"{stat['total_time']['mean']:<12.3f} "
              f"{stat['total_time']['p99']:<12.3f} "
              f"{stat['ttft']['p99']:<12.3f}")
    
    # ç›¸å¯¹æå‡åˆ†æ
    print("\nã€ç›¸å¯¹Baselineæå‡ã€‘\n")
    for stat in all_stats[1:]:
        qps_change = (stat['qps'] / baseline['qps'] - 1) * 100
        resp_change = (1 - stat['total_time']['mean'] / baseline['total_time']['mean']) * 100
        ttft_change = (1 - stat['ttft']['mean'] / baseline['ttft']['mean']) * 100
        
        print(f"æ–¹æ³•: {stat['method']}")
        print(f"  QPSå˜åŒ–: {qps_change:+.1f}%")
        print(f"  å“åº”æ—¶é—´å˜åŒ–: {resp_change:+.1f}%")
        print(f"  TTFTå˜åŒ–: {ttft_change:+.1f}%")
        print(f"  æ£€ç´¢æ—¶é—´: {stat['retrieval_time']['mean']:.3f}ç§’")
        if stat['rerank_time']['mean'] > 0:
            print(f"  é‡æ’æ—¶é—´: {stat['rerank_time']['mean']:.3f}ç§’")
        print()
    
    # ä¿å­˜JSONæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"jieduo_benchmark_report_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'test_date': timestamp,
                'knowledge_base': 'jieduo_policies',
                'total_docs': 9,
                'total_chars': 56364,
                'total_chunks': 142,
                'num_methods': len(all_stats),
                'requests_per_method': TOTAL_REQUESTS,
                'concurrency': CONCURRENCY
            },
            'performance_stats': all_stats
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    # åŒæ—¶ä¿å­˜åŸå§‹ç»“æœç”¨äºè´¨é‡è¯„ä¼°
    results_filename = f"jieduo_benchmark_results_{timestamp}.json"
    with open(results_filename, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': timestamp,
            'results': {method: [
                {
                    'query': r['query'],
                    'answer': r['answer'],
                    'retrieval_method': r['retrieval_method']
                } for r in results
            ] for method, results in all_results_dict.items()}
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ ç­”æ¡ˆç»“æœå·²ä¿å­˜: {results_filename}")
    print("="*80 + "\n")

if __name__ == "__main__":
    asyncio.run(main())